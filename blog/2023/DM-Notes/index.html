<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Notes of Diffusion Models | Yiming Che (车一鸣) </title> <meta name="author" content="Yiming Che"> <meta name="description" content="basics of diffusion models"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/che.jpg?cb45d92e8d9c4d4cdb80894d70e4a1ef"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://soloche.github.io/blog/2023/DM-Notes/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Yiming Che (车一鸣) </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Notes of Diffusion Models</h1> <p class="post-meta"> Created in March 06, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/bayes"> <i class="fa-solid fa-hashtag fa-sm"></i> Bayes</a>   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep-Learning</a>   <a href="/blog/tag/diffusion-model"> <i class="fa-solid fa-hashtag fa-sm"></i> Diffusion-Model</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Table of Contents</strong></p> <ul> <li> <a href="#revisit-of-denoising-diffusion-probabilistic-models-ddpm">Revisit of Denoising Diffusion Probabilistic Models (DDPM)</a> <ul> <li><a href="#ddpm-formulation">DDPM Formulation</a></li> <li><a href="#ddpm-forward-process-encoding">DDPM Forward Process (Encoding)</a></li> <li><a href="#ddpm-reverse-process-decoding">DDPM Reverse Process (Decoding)</a></li> <li> <a href="#training-elbo">Training: ELBO</a> <ul> <li><a href="#parameterization-on-l_t">Parameterization on $L_t$</a></li> <li><a href="#l_t-and-l_0">$L_T$ and $L_0$</a></li> </ul> </li> <li><a href="#implementation">Implementation</a></li> </ul> </li> <li> <a href="#connection-with-ddim">Connection with DDIM</a> <ul> <li><a href="#accelerated-inference">Accelerated Inference</a></li> </ul> </li> <li> <a href="#connection-with-score-based-dm">Connection with Score-based DM</a> <ul> <li><a href="#score-and-score-matching">Score and Score Matching</a></li> <li><a href="#ddpm-to-score-matching-tweedies-formula">DDPM to Score Matching (Tweedie’s Formula)</a></li> <li> <a href="#guidance-from-score">Guidance from Score</a> <ul> <li><a href="#classifier-guidance">Classifier Guidance</a></li> <li><a href="#classifier-free-guidance">Classifier-free Guidance</a></li> </ul> </li> </ul> </li> <li> <a href="#noise-conditional-score-networks-ncsn">Noise Conditional Score Networks (NCSN)</a> <ul> <li> <a href="#langevin-dynamics-sde">Langevin Dynamics (SDE)</a> <ul> <li><a href="#sampling">Sampling</a></li> </ul> </li> </ul> </li> </ul> <h1 id="revisit-of-denoising-diffusion-probabilistic-models-ddpm">Revisit of Denoising Diffusion Probabilistic Models (DDPM)</h1> <p>Some good reviews:</p> <ol> <li><a href="https://theaisummer.com/diffusion-models/?fbclid=IwAR1BIeNHqa3NtC8SL0sKXHATHklJYphNH-8IGNoO3xZhSKM_GYcvrrQgB0o" rel="external nofollow noopener" target="_blank">How diffusion models work: the math from scratch</a></li> <li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" rel="external nofollow noopener" target="_blank">What are Diffusion Models?</a></li> <li><a href="https://yang-song.net/blog/2021/score/" rel="external nofollow noopener" target="_blank">Generative Modeling by Estimating Gradients of the Data Distribution</a></li> <li><a href="https://ar5iv.labs.arxiv.org/html/2208.11970" rel="external nofollow noopener" target="_blank">Understanding Diffusion Models: A Unified Perspective</a></li> <li><a href="https://arxiv.org/abs/2101.03288" rel="external nofollow noopener" target="_blank">How to Train Your Energy-Based Models</a></li> </ol> <h2 id="ddpm-formulation">DDPM Formulation</h2> <p>Given the data distribution $\x_0\sim q(\x_0)$ which is unknown, we want to learn an approximation $p_\theta (\x_0)$ that we can sample from. It is similar to variational autoencoder (VAE) or hierarchical VAE in the form, e.g., it also has encoding process (forward process) and decoding process (reverse process) and minimizes ELBO, but with multiple high dimensional latent variables.</p> <p>Diffusion models are latent variable models with the formulation (Markov chain)</p> \[p_\theta(\x_0) = \int p_\theta(\x_{0:T})d\x_{1:T} \space \text{where} \space p_\theta(\x_{0:T}) = p(\x_T)\prod_{t=1}^{T}p_\theta(\x_{t-1}\mid\x_t).\] <p>The latent variables are ${\x_1,…,\x_T}$ with the same dimensionality as the data $\x_0$ and their joint $p_\theta(\x_{0:T})$ is called the reverse process (decoding) starting at $p(\x_T)=\N(0,\I)$. The approximate posterior $q(\x_{1:T}\mid\x_0)$, called the forward process, is fixed to another Markov chain</p> \[q(\x_{1:T}\mid\x_0) = \prod_{t=1}^{T}q(\x_t\mid\x_{t-1}).\] <p>Compared to other latent variable models, e.g., VAE, it has no learnable parameters in the approximate posterior $q$ (encoding). In this process, the data $\x_0$ is transformed to $\x_T$ by gradually adding Gaussian noise. To recover the data distribution, the ELBO is maximized as</p> \[\begin{align*} \max_{\theta} \log p_\theta(\x_0) &amp;= \log \int \frac{p_\theta(\x_{0:T})q(\x_{1:T}\mid\x_0)}{q(\x_{1:T}\mid\x_0)}d\x_{1:T}\\ &amp;= \log \mathbb{E}_{\x_{1:T}\sim q(\x_{1:T}\mid\x_0)}\sbr{\frac{p_\theta(\x_{0:T})}{q(\x_{1:T}\mid\x_0)}} \\ &amp;\geq \mathbb{E}_{\x_{1:T}\sim q(\x_{1:T}\mid\x_0)}\sbr{\log \frac{p_\theta(\x_{0:T})}{q(\x_{1:T}\mid\x_0)}}\\ &amp;= -KL\sbr{q(\x_{1:T}\mid\x_0)\mid p_\theta(\x_{0:T})}. \end{align*}\] <h2 id="ddpm-forward-process-encoding">DDPM Forward Process (Encoding)</h2> <p>The original data $\x_0\sim q(\x_0)$ and the Markov chain assumes we add noise to the data $\x_0$ in each time step $t\in[1,T]$ with transition kernel $q(\x_t\mid\x_{t-1})$ which is usually handcrafted as</p> \[q(\x_t\mid\x_{t-1}) = \N\nbr{\x_t;\sqrt{1-\beta_t}\x_{t-1},\beta_t\I}\] <p>where $\beta_t\in (0,1)$ is a hyperparameter. A closed form of dependence according to the reparameterization trick:</p> \[\begin{align*} \x_t &amp;= \sqrt{1-\beta_t}\x_{t-1} + \sqrt{\beta_t}\bm{\epsilon}_{t-1} \quad \text{where} \quad \bm{\epsilon}_{t-1}\sim \N\nbr{\bm{0},\bm{I}}\\ &amp;= \sqrt{\alpha_t}\x_{t-1} + \sqrt{1-\alpha_t}\bm{\epsilon}_{t-1} \quad \text{where} \quad \alpha_t = 1-\beta_t \end{align*}\] <p>Furthermore, with the addition of two Gaussian random variable, we can trace back to the data $\x_0$</p> \[\begin{align} \x_t &amp;= \sqrt{\alpha_t\alpha_{t-1}}\x_{t-2} + \sqrt{\alpha_t-\alpha_t\alpha_{t-1}}\bm{\epsilon}_{t-2} + \sqrt{1-\alpha_t}\bm{\epsilon}_{t-1} \nonumber\\ &amp;= \sqrt{\alpha_t\alpha_{t-1}}\x_{t-2} + \sqrt{1-\alpha_{t}\alpha_{t-1}} \bm{\epsilon} \quad \text{where} \quad \bm{\epsilon}\sim \N\nbr{\bm{0},\bm{I}}\nonumber\\ &amp; \qquad ...\nonumber\\ &amp;= \sqrt{\bar{\alpha}_t}\x_{0} + \sqrt{1-\bar{\alpha}_{t}} \bm{\epsilon} \end{align}\\\] <p>where $\bar{\alpha}_ t = \prod_{i=1}^t \alpha_i $. Usually, $\alpha_i$ will decrease along with $t$, and therefore $\bar{\alpha}_t \rightarrow 0$ when $t \rightarrow \infty$.</p> <h2 id="ddpm-reverse-process-decoding">DDPM Reverse Process (Decoding)</h2> <p>To generate a new sample or reverse from $\x_T\sim\N(0,\I)$, we need to know $q(\x_{t-1} \mid \x_t)$ which is unavailable in practice for decoding. However, we know it is also Gaussian according to the Bayes’ theorem. To make it tractable, we use $q(\x_{t-1} \mid \x_t, \x_0)$ which is conditioned on $\x_0$, which can be written as</p> \[q(\x_{t-1} \vert \x_t, \x_0) = q(\x_t\mid\x_{t-1},\x_0)\frac{q(\x_{t-1}\mid\x_0)}{q(\x_t\mid\x_0)} = \mathcal{N}(\x_{t-1}; \color{blue}{\tilde{\bm{\mu}}}(\x_t, \x_0), \color{red}{\tilde{\beta}_t} \mathbf{I}),\] <p>where</p> <p>\(\begin{align} \tilde{\beta}_t &amp;= \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t \nonumber\\ \tilde{\bm{\mu}}_t (\x_t, \x_0) &amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \x_0 \nonumber\\ &amp;= \frac{1}{\sqrt{\alpha_t}} \Big( \x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \bm{\epsilon}_t \Big) = \tilde{\bm{\mu}}_t \end{align}\) with $\x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(\x_t - \sqrt{1 - \bar{\alpha}_t}\bm{\epsilon}_t)$ (derived from Eq. (1)). The details of derivations can be found <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" rel="external nofollow noopener" target="_blank">here</a> (complete the square).</p> <p>Note that $q(\x_{t-1} \mid \x_t, \x_0) = q(\x_{t-1} \mid \x_t)$ due to Markovian property. The decoder $p_\theta$ with parameters $\theta$ is used to approximate $q(\x_{t-1} \mid \x_t, \x_0)$ with the same form as $q(\x_{t-1} \mid \x_t, \x_0)$ (Gaussian), i.e.,</p> \[p_\theta(\x_{t-1} \mid \x_{t}) = \N\nbr{\x_{t-1}\mid \bm{\mu}_\theta(\x_t, t), \bm{\Sigma}_\theta(\x_t, t)}.\] <h2 id="training-elbo">Training: ELBO</h2> <p>Our objective is to maximize the ELBO $-KL\sbr{q(\x_{1:T}\mid\x_0)\mid p_\theta(\x_{0:T})}$ which is equivalent to minimize the negative ELBO</p> \[\begin{align*} L &amp;= \mathbb{E}_{\x_{1:T}\sim q(\x_{1:T}\mid\x_0)}\sbr{\log \frac{q(\x_{1:T}\mid\x_0)}{p_\theta(\x_{0:T})}}\\ &amp;= \mathbb{E}_{\x_{1:T}\sim q(\x_{1:T}\mid\x_0)}\sbr{\log \frac{\prod_{t=1}^{T} q(\x_{t}\mid\x_{t-1})}{p_\theta(\x_T)\prod_{t=1}^{T} p_\theta(\x_{t-1}\mid\x_{t})}}\\ &amp;= \mathbb{E}_{\x_{1:T}\sim q(\x_{1:T}\mid\x_0)}\sbr{-\log p_\theta(\x_T) + \sum_{t=2}^T\log \frac{q(\x_t\mid\x_{t-1})}{p_\theta(\x_{t-1}\mid\x_t)} + \log\frac{q(\x_1\mid\x_0)}{p_\theta(\x_0\mid\x_1)}}\\ &amp;= \mathbb{E}_{\x_{1:T}\sim q(\x_{1:T}\mid\x_0)}\sbr{-\log p_\theta(\x_T) + \sum_{t=2}^T\log \nbr{\frac{q(\x_{t-1}\mid\x_{t},\x_0)}{p_\theta(\x_{t-1}\mid\x_t)}\frac{q(\x_t\mid\x_0)}{q(\x_{t-1}\mid\x_0)}} + \log\frac{q(\x_1\mid\x_0)}{p_\theta(\x_0\mid\x_1)}}\\ &amp;= \mathbb{E}_{\x_{1:T}\sim q(\x_{1:T}\mid\x_0)}\sbr{-\log p_\theta(\x_T) + \sum_{t=2}^T\log \frac{q(\x_{t-1}\mid\x_{t},\x_0)}{p_\theta(\x_{t-1}\mid\x_t)} + \log \frac{q(\x_T\mid\x_0)}{q(\x_{1}\mid\x_0)} + \log\frac{q(\x_1\mid\x_0)}{p_\theta(\x_0\mid\x_1)}}\\ &amp;= \mathbb{E}_{\x_{1:T}\sim q(\x_{1:T}\mid\x_0)}\sbr{\log \frac{q(\x_T\mid\x_0)}{p(\x_T)} + \sum_{t=2}^T\log \frac{q(\x_{t-1}\mid\x_{t},\x_0)}{p_\theta(\x_{t-1}\mid\x_t)} - \log p_\theta(\x_0\mid\x_1)}\\ &amp;= \underbrace{KL\sbr{q(\x_T\mid\x_0)\mid p(\x_T)}}_{L_T} + \sum_{t=2}^T \underbrace{\mathbb{E}_{\x_t\sim q(\x_t\mid\x_0)}\sbr{KL\sbr{q(\x_{t-1}\mid\x_{t},\x_0)\mid p_\theta(\x_{t-1}\mid\x_t)}}}_{L_{t}} - \underbrace{\mathbb{E}_{\x_{1}\sim q(\x_{1}\mid\x_0)}\sbr{\log p_\theta(\x_0\mid\x_1)}}_{L_0} \end{align*}\] <h3 id="parameterization-on-l_t">Parameterization on $L_t$</h3> <p>For $L_t$, we assume the decoder $p_\theta$ has the same form as $q(\x_{t-1}\mid\x_t, \x_0)$ (see Eq. (2)), and the mean $\bm{\mu}_\theta$ is parameterized as</p> \[\bm{\mu}_\theta = \frac{1}{\sqrt{\alpha_t}} \nbr{\x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \bm{\epsilon}_\theta(\x_t, t)}\] \[p_\theta(\x_{t-1}\mid\x_t) = \N\nbr{\x_{t-1}; \frac{1}{\sqrt{\alpha_t}} \Big( \x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \bm{\epsilon}_\theta(\x_t, t) \Big), \bm{\Sigma}_\theta(\x_t, t)}\] <p>In the above case, the $\bm{\epsilon}_\theta(\x_t, t)$ is the output of the backbone model (usually U-net) which is used to approximate the added noise $\bm{\epsilon}_t$ in the forward process.</p> <p>The KL divergence between two Gaussian:</p> \[_{KL}(p||q) = \frac{1}{2}\left[\log\frac{|\Sigma_q|}{|\Sigma_p|} - d + (\bm{\mu_p}-\bm{\mu_q})^T\Sigma_q^{-1}(\bm{\mu_p}-\bm{\mu_q}) + tr\left\{\Sigma_q^{-1}\Sigma_p\right\}\right]\] <p>We set $\bm{\Sigma}_\theta(\x_t, t) = \sigma_t^2\bm{I}$ where $\sigma_t^2 = \tilde{\beta}_t$ or $\sigma_t^2 = \beta_t$ \(\begin{align} L_t &amp;= \mathbb{E}_{\x_0, \bm{\epsilon}} \sbr{\frac{1}{2\sigma_t^2} \| \tilde{\bm{\mu}}_t(\x_t, \x_0) - \bm{\mu}_\theta(\x_t, t) \|^2 } \nonumber\\ &amp;= \mathbb{E}_{\x_0, \bm{\epsilon}} \sbr{\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \sigma_t^2} \|\bm{\epsilon}_t - \bm{\epsilon}_\theta(\x_t, t)\|^2} \nonumber\\ &amp;= \mathbb{E}_{\x_0, \bm{\epsilon}} \sbr{\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \sigma_t^2} \|\bm{\epsilon}_t - \bm{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\x_{0} + \sqrt{1-\bar{\alpha}_{t}} \bm{\epsilon}_t, t)\|^2} \\ \end{align}\)</p> <p>Eq. (3) is further reduced to</p> <p>\(\begin{equation} L_{\text{simple}}(\theta) := \mathbb{E}_{\x_0, \bm{\epsilon}} \sbr{\|\bm{\epsilon}_t - \bm{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\x_{0} + \sqrt{1-\bar{\alpha}_{t}} \bm{\epsilon}_t, t)\|^2}, \end{equation}\) where the weight term is removed for better sample quality.</p> <p>From another perspective, $\bm{\mu}_\theta$ can be parameterized as</p> \[\bm{\mu}_\theta = \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \tilde{\x}_\theta(\x_t,t),\] <p>where $\tilde{\x}_\theta(\x_t,t)$ is the output of the backbone model (U-net) which is used to predict the data $\x_0$ directly.</p> <h3 id="l_t-and-l_0">$L_T$ and $L_0$</h3> <p>$L_T$ is considered a constant and ignored in the training (if $\beta_t$ is fixed). $L_0$ can be regraded as reconstruction error (VAE settings), i.e., $t=1$ in Eq. (4). More details can be found in the <a href="https://arxiv.org/abs/2006.11239" rel="external nofollow noopener" target="_blank">DDPM paper Sec. 3.3</a>.</p> <h2 id="implementation">Implementation</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/post_img/DDPM-algo-480.webp 480w,/assets/post_img/DDPM-algo-800.webp 800w,/assets/post_img/DDPM-algo-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/post_img/DDPM-algo.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Traning and sampling process (Source: DDPM paper) </div> <h1 id="connection-with-ddim">Connection with DDIM</h1> <p>DDIM is proposed to accelerate the inference of DDPM. The formulation is slightly different but the training is proved to be the same.</p> <p>The forward process is non-Markovian. Consider a family $Q$, indexed by a real vector $\sigma\in\R^T$, the joint is now conditioned on $\x_0$: $q_\sigma(\x_{1:T}\mid\x_0) = q_\sigma(\x_T\mid\x_0)\prod_{i=2}^Tq_\sigma(\x_{t-1}\mid\x_{t},\x_0)$ where</p> \[\begin{equation} q_\sigma(\x_{t-1}\mid\x_{t},\x_0) = \N\nbr{\sqrt{\bar{\alpha}_{t-1}}\x_0 + \sqrt{1-\bar{\alpha}_{t-1}-\sigma_t^2}\frac{\x_t-\sqrt{\bar{\alpha}_{t}}\x_0}{\sqrt{1-\bar{\alpha}_{t}}},\sigma_t^2\bm{I}} \end{equation}\] <p>The Eq. (4) is selected to satisfy the joint and $q_\sigma(\x_t\mid\x_0) = \N\nbr{\sqrt{\bar{\alpha}_t}, (1-\bar{\alpha}_t)\bm{I}}$.</p> <p>The forward process is obtained by $q_\sigma(\x_t\mid\x_{t-1},\x_0) = \frac{q_\sigma(\x_{t-1}\mid\x_{t},\x_0)q_\sigma(\x_t\mid\x_0)}{q_\sigma(\x_{t-1}\mid\x_0)}$. It is also Gaussian and the magnitude controls the randomness in the forward process. If we set $\sigma_t = 0$, the forward process becomes deterministic.</p> <p>The reverse process is similar to the DDPM. The joint $p_\theta(\x_{0:T})$ is used to approximate the $q_\sigma(\x_{t-1}\mid\x_{t},\x_0)$ by minimization of KL-divergence and the training objective is the same as $L_{\text{simple}}$ of DDPM (<a href="https://arxiv.org/abs/2010.02502" rel="external nofollow noopener" target="_blank">Theorem 1 in DDIM paper</a>). We can let the model (U-net) predict either $\x_0$ directly or the noise $\bm{\epsilon}_t$. For example (noise prediction),</p> \[f_\theta(\x_t) = \frac{\x_t-\sqrt{1-\bar{\alpha}_t}\bm{\epsilon}_{\theta}(\x_t,t)}{\sqrt{\bar{\alpha}_t}} = \tilde{\x}_0\] <p>According to Eq. (5),</p> \[\begin{align} \x_{t-1} &amp;= \sqrt{\bar{\alpha}_{t-1}}\tilde{\x}_0 + \sqrt{1-\bar{\alpha}_{t-1}-\sigma_t^2}\frac{\x_t-\sqrt{\bar{\alpha}_{t}}\tilde{\x}_0}{\sqrt{1-\bar{\alpha}_{t}}} + \sigma_t\bm{\epsilon}\\ &amp;= \sqrt{\bar{\alpha}_{t-1}}\nbr{\frac{\x_t-\sqrt{1-\bar{\alpha}_t}\bm{\epsilon}_\theta(\x_t,t)}{\sqrt{\bar{\alpha}_{t}}}} + \sqrt{1-\bar{\alpha}_{t}-\sigma_t^2}\bm{\epsilon}_\theta(\x_t,t) + \sigma_t\bm{\epsilon} \end{align}\] <p>$\sigma_t$ is set to $0$ in DDIM and the forward process becomes deterministic and the reverse process becomes implicit probabilistic model.</p> <h2 id="accelerated-inference">Accelerated Inference</h2> <p>In DDPM, we need to go through every forward steps to sample in backward process due to Markovian property. DDIM proposes to use a subset of total time steps to sample in reverse process, i.e., ${\x_{\tau_1},…,\x_{\tau_S}}\subset{\x_1,…,\x_T}$. From another perspective, the interval between two time steps is increased in the reverse process, e.g., $\tau_{s+1}-\tau_s = \Delta\tau \geq 1$ where $\Delta\tau$ is a hyperparameter. Now, we are sampling from $q_\sigma(\x_{t-\Delta_\tau}\mid\x_{t},\x_0)$ iteratively. Hence, the reverse process is accelerated. Why it can jump? It is essentially an ODE. Larger jump means more discretization error.</p> <h1 id="connection-with-score-based-dm">Connection with Score-based DM</h1> <h2 id="score-and-score-matching">Score and Score Matching</h2> <p>In order to learn a distribution $p_{data}$, we need to represent it first. Usually, we define</p> \[p_\theta(\x) = \frac{e^{-f_\theta(\x)}}{Z_\theta}\] <p>where it satisfies $p_\theta(\x) \geq 0$ and $\int p_\theta(\x)d\x = 1$. For a dataset ${\x_1,…,\x_N}$, we cannot use MLE to estimate the parameters $\theta$ because the likelihood is intractable due to the normalizing factor $Z_\theta$. Instead, we can use the score function to estimate the parameters. Score of a probability density function $p(\x)$ is defined as $\nabla_{\x}\log p(x)$. For example, if $p$ is Gaussian distributed, $\nabla_{\x}\log p(\x) = -\frac{\x-\bm{\mu}}{\sigma^2} = -\frac{\bm{\epsilon}}{\sigma}$ (standardization). More details can be found in <a href="https://arxiv.org/abs/2101.03288" rel="external nofollow noopener" target="_blank">How to Train Your Energy-Based Models</a>.</p> <p>We want to learn a score model $\bm{s}_\theta(\x)=\nabla_{\x}\log p_\theta = -\nabla_{\x}f_{\theta}(\x)\approx \nabla_{\x}\log p_{data}$. Then, we can draw samples from the approximated score function. Can we draw samples directly from score function? Yes, <strong>Langevin Dynamics</strong>. To train $\bm{s}_\theta$, we minimize the Fisher Divergence, which is also called score matching,</p> \[\begin{equation} D_F\sbr{p_{data}\mid p_\theta} = \mathbb{E}_{p_{data}}\sbr{\frac{1}{2}\left\lVert\nabla_{\x}\log p_{data}(\x) - \bm{s}_\theta(\x)\right\rVert_2^2}. \end{equation}\] <p>However, $p_{data}$ is unknown. Fortunately, it can be replaced by the derivative of $\bm{s}_\theta(\x)$ to eliminate the unknown $p_{data}$ (see the derivation from <a href="https://jmlr.org/papers/v6/hyvarinen05a.html" rel="external nofollow noopener" target="_blank">Estimation of Non-Normalized Statistical Models by Score Matching</a>),</p> \[\begin{equation} D_F\sbr{p_{data}\mid p_\theta} = \mathbb{E}_{p_{data}}\sbr{Tr(\nabla_{\x} \bm{s}_\theta(\x)) + \frac{1}{2}\left\lVert \bm{s}_\theta(\x)\right\rVert_2^2} + \text{Constant}. \end{equation}\] <p>One critical problem is that the score matching is not scalable to deep networks and high dimensional data due to the derivative term.</p> <h2 id="ddpm-to-score-matching-tweedies-formula">DDPM to Score Matching (Tweedie’s Formula)</h2> <p>From Eq. (1), we have the forward process $\x_t\sim\N(\x_t \mid \sqrt{\bar{\alpha}_t}\x_0, (1-\bar{\alpha}_t)\I)$. By Tweedie’s formula, the mean can be approximated as</p> \[\begin{align*} \sqrt{\bar{\alpha}_t}\x_0 &amp;= \x_t + (1-\bar{\alpha}_t)\nabla_{\x_t}\log p(\x_t)\\ \x_0 &amp;= \frac{\x_t}{\sqrt{\bar{\alpha}_t}} + \frac{1-\bar{\alpha}_t}{\sqrt{\bar{\alpha}_t}}\nabla_{\x_t}\log p(\x_t).\\ \end{align*}\] <p>In this case, the $\tilde{\bm{\mu}}_t (\x_t, \x_0)$ can be parameterized as</p> \[\tilde{\bm{\mu}}_t (\x_t, \x_0) = \frac{1}{\sqrt{\alpha}_t} \x_t + \frac{1-\alpha_t}{\sqrt{\alpha}_t}\nabla_{\x_t}\log p(\x_t).\] <p>Then, the backbone model is used to predict the score at time step $t$. The approximation becomes</p> \[\bm{\mu}_\theta = \frac{\x_t}{\sqrt{\bar{\alpha}_t}} + \frac{1-\bar{\alpha}_t}{\sqrt{\bar{\alpha}_t}}\bm{s}_\theta(\x_t, t).\] <p>Finally, the objective becomes</p> \[\begin{align*} L_t &amp;= \mathbb{E}_{\x_0, \bm{\epsilon}} \sbr{\frac{1}{2\sigma_t^2} \| \tilde{\bm{\mu}}_t(\x_t, \x_0) - \bm{\mu}_\theta(\x_t, t) \|^2 }\\ &amp;= \mathbb{E}_{\x_0, \bm{\epsilon}} \sbr{\frac{1}{2\sigma_t^2}\frac{ (1 - \alpha_t)^2 }{\alpha_t} \|\bm{s}_\theta(\x_t, t) - \nabla_{\x_t}\log p(\x_t)\|^2}. \end{align*}\] <p>Note that the true noise and the score looks very similar in the above equation. If we compare two type of $\x_0$ from score and noise, we have $\nabla_{\x_t}\log p(\x_t)=-\frac{1}{\sqrt{1-\bar{\alpha}}}\bm{\epsilon}$.</p> <h2 id="guidance-from-score">Guidance from Score</h2> <p>In guided diffusion models, we approximate the conditional data distribution $p(\x\mid y)$ instead of $p(\x)$. Hence, our goal is to learn the gradient $\nabla_{\x_t}\log p(\x_t\mid y)$ which can be written as</p> \[\begin{equation} \nabla_{\x_t}\log p(\x_t\mid y) = \underbrace{\nabla_{\x_t}\log p(y\mid\x_t)}_{\text{adversarial gradient}} + \underbrace{\nabla_{\x_t}\log p(\x)}_{\text{uncond. gradient}}. \end{equation}\] <h3 id="classifier-guidance">Classifier Guidance</h3> <p>In the classifier guidance, we have a classifier $\bm{C}_\phi$ which is used to predict the label $y$ given noised data $\x_t$. The gradient of the classifier is used as guidance, i.e.,</p> \[\begin{align*} \nabla_{\x_t}\log p(\x_t\mid y) &amp;\approx \nabla_{\x_t}\log C_\phi(y\mid\x_t) + \bm{s}_\theta(\x_t, t)\\ &amp;= \nabla_{\x_t}\log C_\phi(y\mid\x_t) - \frac{1}{\sqrt{1-\bar{\alpha}}}\bm{\epsilon}_\theta(\x_t, t)\\ &amp;= - \frac{1}{\sqrt{1-\bar{\alpha}}} \underbrace{\nbr{\bm{\epsilon}_\theta(\x_t, t) - \sqrt{1-\bar{\alpha}}\nabla_{\x_t}\log C_\phi(y\mid\x_t)}}_{\text{new predictor}}. \end{align*}\] <p>Note that $\nabla_{\x_t}\log p(\x_t)=-\frac{1}{\sqrt{1-\bar{\alpha}}}\bm{\epsilon}$. Then, the new predictor can be combined with a parameter $w$ to control the guidance strength, i.e.,</p> \[\begin{equation} \tilde{\bm{\epsilon}}(\x_t, t) = \bm{\epsilon}_\theta(\x_t, t) - w\sqrt{1-\bar{\alpha}}\nabla_{\x_t}\log C_\phi(y\mid\x_t), \end{equation}\] <p>where we have the form</p> \[\nabla_{\x_t}\log p(\x_t) + \gamma \nabla_{\x_t}\log p(y\mid\x_t).\] <p>One of the drawbacks of the classifier guidance is that the classifier has to be trained separately. In most of work, $\bm{\epsilon}_\theta(\x_t, t)$ is replaced by the conditioned version $\bm{\epsilon}_\theta(\x_t, t, y)$ in Eq. (11).</p> <h3 id="classifier-free-guidance">Classifier-free Guidance</h3> <p>To avoid the classifier, we need to reconsider the term $\nabla_{\x_t}\log p(y\mid\x_t)$. With Bayes’ theorem, we have</p> \[\begin{align*} \nabla_{\x_t}\log p(y\mid\x_t) &amp;= \nabla_{\x_t}\log p(\x_t\mid y) - \nabla_{\x_t}\log p(\x_t)\\ &amp;\approx \bm{s}_\theta(\x_t, t, y) - \bm{s}_\theta(\x_t, t)\\ &amp;= -\frac{1}{\sqrt{1-\bar{\alpha}}}\nbr{\bm{\epsilon}_\theta(\x_t, t, y)-\bm{\epsilon}_\theta(\x_t, t)} \end{align*}\] <p>The idea is that we use a new model $\bm{\epsilon}_\theta(\x_t, t, y)$ to learn the conditioned score. To obtain the approximated $\nabla_{\x_t}\log p(\x_t\mid y)$, we just add the unconditioned score, i.e.,</p> \[\begin{align*} \nabla_{\x_t}\log p(\x_t\mid y) &amp;\approx \gamma\nabla_{\x_t}\log p(y\mid\x_t) + \nabla_{\x_t}\log p(\x_t)\\ &amp;\approx -\frac{\gamma}{\sqrt{1-\bar{\alpha}}}\nbr{\bm{\epsilon}_\theta(\x_t, t, y)-\bm{\epsilon}_\theta(\x_t, t)} - \frac{1}{\sqrt{1-\bar{\alpha}}}\bm{\epsilon}_\theta(\x_t, t)\\ &amp;=- \frac{1}{\sqrt{1-\bar{\alpha}}}\underbrace{\nbr{\gamma\bm{\epsilon}_\theta(\x_t, t, y) - (\gamma-1)\bm{\epsilon}_\theta(\x_t, t)}}_{\text{new predictor}}. \end{align*}\] <p>If we set $\gamma=w+1$, we have the same form as the one in the classifier-free paper. Hence, the new predictor can be written as</p> \[\begin{equation} \tilde{\bm{\epsilon}}(\x_t, t, y) = (w+1)\bm{\epsilon}_\theta(\x_t, t, y) - w\bm{\epsilon}_\theta(\x_t, t). \end{equation}\] <p>The advantage of the classifier-free guidance is that we do not need to train the classifier separately. The conditioned model $\bm{\epsilon}_\theta(\x_t, t, y)$ and unconditioned model $\bm{\epsilon}_\theta(\x_t, t, \emptyset)$ are learned jointly by “turn off” a certain ratio of the labels (looks like dropout normalization). For example, if we set the ratio (threshold) to $p$, we generate a mask <code class="language-plaintext highlighter-rouge">mask = torch.rand(cemb.shape[0])&lt;threshold</code> where <code class="language-plaintext highlighter-rouge">cemb</code> is a batch of label embeddings. Then, we “turn off” these labels, i.e., <code class="language-plaintext highlighter-rouge">cemb[np.where(mask)[0]] = 0</code>. Finally, we add time embeddings and label embeddings, i.e., <code class="language-plaintext highlighter-rouge">emb = cemb + temb</code> to as the input to the backbone model.</p> <h1 id="noise-conditional-score-networks-ncsn">Noise Conditional Score Networks (NCSN)</h1> <p>In <a href="https://arxiv.org/abs/1907.05600" rel="external nofollow noopener" target="_blank">Generative Modeling by Estimating Gradients of the Data Distribution</a>, the authors propose a score-based model called Noise Conditional Score Networks (NCSN). To circumvent the direct computation of $Tr(\nabla_{\x}^2\log p_{\bm{\theta}}(\x))$, <strong>Denoising Score Matching</strong> or <strong>Sliced Score Matching</strong> are proposed. Here, we focus on the former. The idea is that we create a data distribution that very close to the true data distribution by perturbing the data $\x$ with a pre-specified noise distribution $q_{\sigma}(\tilde{\x}\mid\x)$ and the perturbed distribution is $q(\tilde{\x}) := \int p_{data}(x)q_{\sigma}(\tilde{\x}\mid\x)d\x$. To learn the score of data distribution, we minimize the Fisher divergence</p> \[\begin{align} D_F\sbr{q(\tilde{\x})\mid p_\theta(\tilde{\x})} &amp;= \mathbb{E}_{q_{\sigma}(\tilde{\x})}\mathbb{E}_{p_{data}(\x)}\sbr{\frac{1}{2}\left\lVert\bm{s}_\theta(\tilde{\x}) - \nabla_{\tilde{\x}} q_{\sigma}(\tilde{\x})\right\rVert^2} \\ &amp;= \mathbb{E}_{q_{\sigma}(\tilde{\x}\mid\x)}\mathbb{E}_{p_{data}(\x)}\sbr{\frac{1}{2}\left\lVert\bm{s}_\theta(\tilde{\x}) - \nabla_{\tilde{\x}} q_{\sigma}(\tilde{\x}\mid\x)\right\rVert^2 } + C \end{align}\] <p>Note that $\bm{s}_{\theta^*}(\tilde{\x})=\nabla_{\x}q_\sigma(\tilde{\x})$ almost surely by minimizing Eq. (14). However, $\bm{s}_{\theta^*}(\tilde{\x}) = \nabla_{\tilde{\x}} q_{\sigma}(\tilde{\x}) \approx \nabla_{\x}\log p_{data}(\x)$ is true only when the noise level $\sigma$ is small enough, which leads to $q_{\sigma}(\tilde{\x}) \approx p_{data}(\x)$.</p> <p>There are two problems in score matching:</p> <ul> <li> <strong>Inaccurate score estimation in low data density regions:</strong> the data often concentrate on low dimensional manifolds embedded in a high dimensional space (a.k.a., the ambient space). It means that the data don’t cover the whole $\mathbb{R}^D$ space. Hence, the score estimation is inaccurate in the low data density regions. Since the sampling is a iterative process, the inaccurate score estimation will lead to a biased sampling process.</li> <li> <strong>Slow mixing of Langevin dynamics:</strong> sampling process may be very slow if the distribution has 2 modes and they are separated by a low density region. The Langevin dynamics may be trapped in the low density region and cannot move to the other mode.</li> </ul> <p>In NCSN, data are perturbed by different levels of noise. Let $\sigma_1&gt;\sigma_2&gt;…&gt;\sigma_L$ be the noise levels which is a positive geometric sequence. The perturbed data distribution is written as $q_{\sigma_i}(\tilde{\x})=\int p_{data}(\x)p(\tilde{\x} \mid \x)d\x = \int p_{data}(\x)\N(\tilde{\x}\mid \x, \sigma_i) d\x $. We choose the noise function $q_{\sigma_i}(\tilde{\x} \mid \x) = \N(\x,\sigma_i^2\I)$ and $\nabla_{\tilde{\x}}\log q_{\sigma_i}(\tilde{\x}\mid \x) = -\frac{\tilde{\x}-\x}{\sigma_i^2}$. Intuitively, the perturbed data with different noise levels fill the low density regions. It may be regarded as a data augmentation technique. Also, these perturbed data build a “tunnel” between the true data distribution and the prior distribution ($\N(0,I)$), which helps improve the mixing rate of Langevin dynamics on multimodal distributions.</p> <p>For a given noise level $\sigma_i$, the objective is</p> \[\ell_i(\theta;\sigma_i) = \mathbb{E}_{q_{\sigma_i}}\mathbb{E}_{p_{data}}\sbr{\frac{1}{2}\left\lVert\bm{s}_\theta(\tilde{\x},\sigma_i) + \frac{\tilde{\x}-\x}{\sigma_i^2}\right\rVert^2_2}.\] <p>Then, the total objective is</p> \[\mathcal{L}(\theta) = \sum_{i=1}^L\lambda(\sigma_i)\ell_i(\theta;\sigma_i).\] <p>The author found that $\left\lVert\bm{s}_\theta(\tilde{\x},\sigma_i)\right\rVert_2\propto \frac{1}{\sigma_i}$. To balance the contribution of each noise level, the weight $\lambda(\sigma_i)$ is set to $\sigma_i^2$ to make the objective scale-invariant $\frac{\tilde{\x}-\x}{\sigma_i}\sim \N(0,\I)$.</p> <h2 id="langevin-dynamics-sde">Langevin Dynamics (SDE)</h2> <p>It can be represented as Ito’s diffusion</p> \[\begin{aligned} d\x_t &amp;= -\nabla_{\x}V(\x)dt + \sqrt{2}d\bm{w}_t \\ &amp;= -\nabla_{\x}V(\x)dt + \sqrt{2dt}\bm{z}_t, \quad \bm{z}_t\sim\N(0,\I). \end{aligned}\] <p>where $\bm{w}_t\sim\N(0,\bm{t})$ is the standard Wiener process and $V(\x)$ is the potential energy. The steady state distribution of the above SDE can be determined by the <a href="https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation" rel="external nofollow noopener" target="_blank">Fokker-Plank equation</a> which is a partial differential equation (PDE) that describes the evolution of a probability distribution over time under the effect of drift forces and random (or noise) forces. To be more specific, we want to find the stationary distribution $p(\x)$ that satisfies the following equation</p> \[\frac{\partial p(\x,t)}{\partial t} = \frac{\partial }{\partial \x}\Big(\frac{\partial V(\x)}{\partial \x}p(\x,t)\Big) + \frac{\partial^2 p(\x,t)}{\partial \x^2} = 0\] <p>which has the equilibrium distribution $p(\x) \propto e^{-V(\x)}$. We hope that the distribution $p(\x)$ is close to the true data distribution $p_{data}(\x)$ in our case. Recall that $p_\theta(\x) = \frac{e^{-f_\theta(\x)}}{Z_\theta}$, we can set $V(\x) = f_\theta(\x)$ and then $\nabla_{\x}V(\x) = \bm{s}_\theta(\x)$.</p> <h3 id="sampling">Sampling</h3> <p>The discretization of the above SDE can be written as</p> \[\x_{t+\epsilon} = \x_{t} - \epsilon\bm{s}_{\theta}(\x) + \sqrt{2\epsilon}\bm{z}_t.\] <p>The sampling can be done by iteratively updating the data $\x$ with the above equation. In NCSN, the sampling process is slightly modified by using different step length at each noise level (annealed Langevin dynamics). The step length is set to $\alpha_i = \epsilon \frac{\sigma_i}{\sigma_L}$. The sampling process is</p> \[\x_{t} \leftarrow \x_{t-1} + \frac{\alpha_i}{2}\bm{s}_\theta(\x,\sigma_i) + \sqrt{\alpha_i}\bm{z}_i \quad t=0,1,...,T, \quad i=1,...,L.\] <p>Note that there are 2 loops in the sampling process. The outer loop is for the noise level and the inner loop is for the Langevin dynamics.</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yiming Che. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: January 31, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams",packages:{"[+]":["configmacros"]},macros:{R:"{\\mathbb{R}}",f:"{\\bf f}",w:"{\\boldsymbol{w}}",x:"{\\boldsymbol{x}}",I:"{\\boldsymbol{I}}",nbr:["\\left(#1\\right)",1],sbr:["\\left[#1\\right]",1],bm:["\\boldsymbol{#1}",1],bs:["\\boldsymbol{#1}",1],N:"{\\mathcal{N}}",argmax:["\\underset{#1}{\\operatorname{argmax}}",1],argmin:["\\underset{#1}{\\operatorname{argmin}}",1]},inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>